{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from char_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import char_rnn\n",
    "reload(char_rnn)\n",
    "from char_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n",
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"tiny_shakespeare.txt\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# text = text[:10] * 1000\n",
    "print(text[100:200])\n",
    "print(len(text))\n",
    "text = text[:1000]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAl')\n",
      "(100, 'articularise their abundance; our\\nsufferance is a gain to them L')\n",
      "(100, 're we become rakes: for the gods know I\\nspeak this in hunger for')\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "train_size = int(0.8 * len(text))\n",
    "valid_size = int(0.1 * len(text))\n",
    "test_size = len(text) - train_size - valid_size\n",
    "train_text = text[:train_size]\n",
    "valid_text = text[train_size:train_size + valid_size]\n",
    "test_text = text[train_size + valid_size:]\n",
    "\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])\n",
    "print(test_size, test_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 46\n"
     ]
    }
   ],
   "source": [
    "# unique_chars = text[:10] # list(set(text))\n",
    "unique_chars = list(set(text))\n",
    "vocab_size = len(unique_chars)\n",
    "print('vocab size: %d' % vocab_size)\n",
    "vocab_index_dict = {}\n",
    "index_vocab_dict = {}\n",
    "\n",
    "for i, char in enumerate(unique_chars):\n",
    "    vocab_index_dict[char] = i\n",
    "    index_vocab_dict[i] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 2,\n",
       " '!': 1,\n",
       " \"'\": 3,\n",
       " ',': 4,\n",
       " '.': 5,\n",
       " ':': 7,\n",
       " ';': 6,\n",
       " '?': 8,\n",
       " 'A': 9,\n",
       " 'B': 11,\n",
       " 'C': 10,\n",
       " 'F': 12,\n",
       " 'I': 13,\n",
       " 'L': 15,\n",
       " 'M': 14,\n",
       " 'N': 17,\n",
       " 'O': 16,\n",
       " 'R': 19,\n",
       " 'S': 18,\n",
       " 'W': 20,\n",
       " 'Y': 21,\n",
       " 'a': 22,\n",
       " 'b': 24,\n",
       " 'c': 23,\n",
       " 'd': 26,\n",
       " 'e': 25,\n",
       " 'f': 28,\n",
       " 'g': 27,\n",
       " 'h': 30,\n",
       " 'i': 29,\n",
       " 'j': 32,\n",
       " 'k': 31,\n",
       " 'l': 34,\n",
       " 'm': 33,\n",
       " 'n': 36,\n",
       " 'o': 35,\n",
       " 'p': 37,\n",
       " 'r': 39,\n",
       " 's': 38,\n",
       " 't': 41,\n",
       " 'u': 40,\n",
       " 'v': 43,\n",
       " 'w': 42,\n",
       " 'y': 44,\n",
       " 'z': 45}"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "n_unrollings = 10\n",
    "train_batches = BatchGenerator(train_text, batch_size, n_unrollings, vocab_size, \n",
    "                               vocab_index_dict, index_vocab_dict)\n",
    "eval_train_batches = BatchGenerator(train_text, 1, 1, vocab_size,\n",
    "                                    vocab_index_dict, index_vocab_dict)\n",
    "valid_batches = BatchGenerator(valid_text, 1, 1, vocab_size,\n",
    "                               vocab_index_dict, index_vocab_dict)\n",
    "test_batches = BatchGenerator(test_text, 1, 1, vocab_size,\n",
    "                              vocab_index_dict, index_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First Citiz', '\\n\\nFirst Cit', 'ed. resolve', 'e people.\\n\\n', ' have corn ', 'be done: aw', 'e are accou', 'ould reliev', 'some, we mi', 'the leannes']\n",
      "['ar']\n"
     ]
    }
   ],
   "source": [
    "print(batches2string(train_batches.next(), index_vocab_dict))\n",
    "print(batches2string(valid_batches.next(), index_vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.variable_scope.variable_scope>"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'batch_size': batch_size, 'num_unrollings': n_unrollings, 'vocab_size': vocab_size, \n",
    "        'hidden_size': 100, 'max_grad_norm': 5.0, 'embedding_size': 50, \n",
    "        'num_layers': 1}\n",
    "tf.variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.variable_scope('char_rnn') as scope:\n",
    "        train_model = CharRNN(is_training=True, **params)\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        valid_model = CharRNN(is_training=False, **params)\n",
    "        test_model = CharRNN(is_training=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "model_name = 'char_rnn'\n",
    "saved_model_dir = '/tmp/char_rnn/char_rnn'\n",
    "init_from_path = '' #saved_path #'/tmp/saved_char_rnn_model-240'\n",
    "log_dir = '/tmp/char_rnn_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 53.476, speed: 381 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-7\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 38.064, speed: 1070 wps\n",
      "\n",
      "Epoch 1\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 34.123, speed: 467 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-14\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 24.159, speed: 1099 wps\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 26.528, speed: 461 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-21\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 22.252, speed: 1099 wps\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 25.680, speed: 477 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-28\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 22.356, speed: 1083 wps\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 24.955, speed: 474 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-35\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 21.834, speed: 1078 wps\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 24.498, speed: 424 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-42\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 22.025, speed: 1088 wps\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 24.076, speed: 473 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-49\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 21.674, speed: 1099 wps\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 23.529, speed: 473 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-56\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 20.978, speed: 1072 wps\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 23.563, speed: 470 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-63\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 21.208, speed: 1120 wps\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 22.986, speed: 451 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-70\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 20.192, speed: 1125 wps\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 21.962, speed: 462 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-77\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 19.930, speed: 1114 wps\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 21.770, speed: 471 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-84\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 20.093, speed: 1108 wps\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 20.633, speed: 475 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-91\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 19.555, speed: 1134 wps\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 19.910, speed: 460 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-98\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 19.185, speed: 1121 wps\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 19.252, speed: 471 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-105\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 19.020, speed: 1110 wps\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 18.297, speed: 474 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-112\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 18.484, speed: 1094 wps\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 17.696, speed: 471 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-119\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 18.784, speed: 1108 wps\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 16.480, speed: 469 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-126\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 18.666, speed: 1133 wps\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 15.367, speed: 469 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-133\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.039, speed: 1085 wps\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 15.063, speed: 437 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-140\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 18.474, speed: 1115 wps\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 13.999, speed: 468 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-147\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.265, speed: 1049 wps\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 13.210, speed: 463 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-154\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.058, speed: 1072 wps\n",
      "\n",
      "Epoch 22\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 12.864, speed: 474 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-161\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 16.840, speed: 989 wps\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 11.978, speed: 462 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-168\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 16.681, speed: 1104 wps\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 11.659, speed: 474 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-175\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.237, speed: 1114 wps\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 10.782, speed: 465 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-182\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 16.783, speed: 1119 wps\n",
      "\n",
      "Epoch 26\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 10.236, speed: 473 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-189\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 16.596, speed: 1121 wps\n",
      "\n",
      "Epoch 27\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 10.251, speed: 473 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-196\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.910, speed: 1102 wps\n",
      "\n",
      "Epoch 28\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 9.672, speed: 469 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-203\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 18.289, speed: 1006 wps\n",
      "\n",
      "Epoch 29\n",
      "\n",
      "training\n",
      "epoch_size: 7\n",
      "data_size: 800\n",
      "num_unrollings: 10\n",
      "batch_size: 10\n",
      "final ppl: 9.269, speed: 462 wps\n",
      "model saved in /tmp/char_rnn/char_rnn-210\n",
      "\n",
      "validation\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "final ppl: 17.549, speed: 1106 wps\n",
      "\n",
      "test\n",
      "epoch_size: 99\n",
      "data_size: 100\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "9.1%, step:9, perplexity: 10.573, speed: 443 wps\n",
      "19.2%, step:19, perplexity: 13.614, speed: 675 wps\n",
      "29.3%, step:29, perplexity: 10.044, speed: 808 wps\n",
      "39.4%, step:39, perplexity: 15.490, speed: 906 wps\n",
      "49.5%, step:49, perplexity: 15.261, speed: 960 wps\n",
      "59.6%, step:59, perplexity: 16.602, speed: 974 wps\n",
      "69.7%, step:69, perplexity: 16.539, speed: 988 wps\n",
      "79.8%, step:79, perplexity: 15.535, speed: 1024 wps\n",
      "89.9%, step:89, perplexity: 14.862, speed: 1052 wps\n",
      "final ppl: 14.279, speed: 1076 wps\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    writer = tf.train.SummaryWriter(log_dir, session.graph_def)\n",
    "    if init_from_path:\n",
    "        train_model.saver.restore(session, init_from_path)\n",
    "    else:\n",
    "        tf.initialize_all_variables().run()\n",
    "    for i in range(n_epochs):\n",
    "        print('\\nEpoch %d\\n' % i)\n",
    "        print('training')\n",
    "        train_model.run_epoch(session, train_size, train_batches, is_train=True, verbose=False, summary_writer=writer)\n",
    "\n",
    "        saved_path = train_model.saver.save(session, saved_model_dir, \n",
    "                                            global_step=train_model.global_step)\n",
    "        print('model saved in %s\\n' % saved_path)\n",
    "        print('validation')\n",
    "        valid_model.run_epoch(session, valid_size, valid_batches, \n",
    "                              is_train=False, verbose=False)\n",
    "    print('\\ntest')\n",
    "    test_model.run_epoch(session, test_size, test_batches, \n",
    "                         is_train=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/char_rnn/char_rnn-210'"
      ]
     },
     "execution_count": 1201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.zero_state\n",
    "saved_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "\n",
      "Firs the are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are a\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    train_model.saver.restore(session, saved_path)\n",
    "    print(valid_model.sample_seq(session, 400, vocab_index_dict, index_vocab_dict, max_prob=True,\n",
    "                                 prime_text=train_text[:10]))\n",
    "    # \"First Citizen:\\nWe are accounted poor \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(train_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try_text = '10987098709'\n",
    "# try_text = '12345678901'\n",
    "try_text = 'First sissssssssssss'\n",
    "try_text = train_text[:20]\n",
    "# try_text = valid_text[80:100]\n",
    "try_batches = BatchGenerator(try_text, 1, 1, vocab_size, vocab_index_dict, index_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_size: 19\n",
      "data_size: 20\n",
      "num_unrollings: 1\n",
      "batch_size: 1\n",
      "47.4%, step:9, perplexity: 1.052, speed: 400 wps\n",
      "final ppl: 1.078, speed: 602 wps\n",
      "1.07818488991\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    train_model.saver.restore(sess, saved_path)\n",
    "    print(valid_model.run_epoch(sess, len(try_text), try_batches,\n",
    "                        is_train=False, verbose=True, debug=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First CitiFirst Citi'"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ', 1: 'C', 2: 'F', 3: 'i', 4: 's', 5: 'r', 6: 't'}"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0, 'C': 1, 'F': 2, 'i': 3, 'r': 5, 's': 4, 't': 6}"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1053-91fd808fcc8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mindex_vocab_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtry_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'F'"
     ]
    }
   ],
   "source": [
    "[index_vocab_dict[int(t)] for t in try_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('a %s' % 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1]])\n",
    "a[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
